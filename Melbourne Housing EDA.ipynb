{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Blog: Exploratory Data Analysis Workshop in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will be analyzing Melbourne Housing data to see if real estate is really *booming* (as described by the owner of the dataset). This dataset is from Kaggle, found [here](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import all the Needed Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting any project, always make sure you have all the proper packages to manipulate the dataset and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #used for working with dataframes—our dataset\n",
    "import numpy as np #used to manipulate arrays\n",
    "import matplotlib.pyplot as plt #for making visuals\n",
    "import seaborn as sns #for making visuals too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tip: use the \"Run\" button to run a cell, or the shortcut command-R, if on a Mac, with the cell highlighted to run it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you found the necessary data, the next step is to load the data on jupyter. There are various ways you can load the data depending on where it came from:\n",
    "* Download the data manually and load it from its location in your files\n",
    "* Use the `urlretrieve` function from the `urllib.request` to download CSV files from a raw URL\n",
    "\n",
    "In most cases, it's easiest to download the data in the same folder as your jupyter notebook (as we had already done) and just load it with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df = pd.read_csv('melb_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then take a look at the first few rows of our dataframe by issuing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataframe is saved in the variable `melborne_df` and we can use it analyze the data. Let's look at the columns our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking over the data, let's start cleaning it.\n",
    "\n",
    "We'll begin by only taking a subset of the data that we actually want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column names we want\n",
    "cols = ['Rooms', 'Type', 'Price', 'Date', 'Bathroom', 'Car', 'Regionname',\n",
    "       'Landsize', 'YearBuilt', 'CouncilArea', 'Lattitude', 'Longtitude', 'Propertycount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df = melbourne_df[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the information on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melbourne_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the data in integer/float data, but we can see that `Date`, `Type`, and `CouncilArea` are object type. There is a date type in pandas we can use which many be useful as well as a function that is useful for categorical variables like `Type`.\n",
    "\n",
    "We can also see that some columns have less than 13580 non-null values, meaning some infomation is missing. Let's deal with that first.\n",
    "\n",
    "The YearBuilt has the most NA values, and we would like to work with that data. We will drop all the rows that are NA for year built (and we understand we will be losing a lot of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.dropna(subset=['YearBuilt'], inplace=True) \n",
    "#note that inplace=True is need to change the ACTUAL dataset, or else a copy will be returned instead\n",
    "melbourne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's only a few of the `Car` values missing (the number of car spaces on the lot). For this column we are going to replace the NA values with the median number of car spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df['Car'].fillna(melbourne_df['Car'].median(), inplace=True)\n",
    "melbourne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "melbourne_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `CouncilArea`, let's just drop the whole column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.drop(columns=['CouncilArea'], inplace=True)\n",
    "melbourne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look over the integer data and see what needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melbourne_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df = melbourne_df[melbourne_df['Landsize'] > 100]\n",
    "#at least 100 square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df = melbourne_df[melbourne_df['Bathroom'] > 0]\n",
    "#at least 1 bathroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df = melbourne_df[melbourne_df['YearBuilt'] > 1196]\n",
    "#1196 does not sounds right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fix the Date and YearBuilt datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melbourne_df['YearBuilt'] =  pd.to_datetime(dict(year=melbourne_df['YearBuilt'], month=1, day=1))\n",
    "#using 1 for month and day since DateTime requires these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melbourne_df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_df['Date'] =  pd.to_datetime(melbourne_df['Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "melbourne_df['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll deal with the Type column. Since there are different values, we will be using Pandas' `get_dummies` function to make a column for each categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "melbourne_df = pd.get_dummies(melbourne_df, prefix=['type'], columns=['Type'])\n",
    "melbourne_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some exploratory data analysis to see what information we can gather from our data before we start asking more specific questions.\n",
    "\n",
    "Let's try answering the following questions:\n",
    "\n",
    "1. What is the average number of rooms in this dataset and what is the median number of rooms? (Hint: use [] or . to select a column from the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanrooms = melbourne_df['Rooms'].mean()\n",
    "medianrooms = ???\n",
    "\n",
    "print(f'The average number of rooms for a property is Melbourne is {meanrooms} and the most common number of rooms is {medianrooms}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the average price of properties built after 1970? (Hint: in the data cleaning process, we used a function to only look at data where a column value was above a certain threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgprice = ???\n",
    "\n",
    "print(f'The average price of a property built after 1970 is {avgprice}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the average price of property by region, given that the property has more than 2 rooms? (Hint: the [groupby function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) is very useful and the answer should be a Series—one column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what sorts of visualizations we can make. First, let's plot of histogram of the prices of properties in Melbourne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Prices of Properties in Melbourne')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Number of properties')\n",
    "\n",
    "plt.hist(melbourne_df['Price'], melbourne_df['Price'].count(), color='purple');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like outliers have made the graph pretty useless. Query the dataframe so that we only see a histogram of properties that fall within the IQR (25%-75%). (Hint: Use the [quantile function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IQRprices_df = ???\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Prices of Properties in Melbourne')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Number of properties')\n",
    "\n",
    "plt.hist(IQRprices_df['Price'], IQRprices_df['Price'].count(), color='purple');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a little better. In the future, we can use [subplots](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html) to plot the range of prices for each type of property, or by each region to really understand the price distribution.\n",
    "\n",
    "Let's make a visual of the number of houses built over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new dataframe with date information\n",
    "timebuilt_df = melbourne_df.groupby('YearBuilt').count().reset_index()[['YearBuilt','Rooms']]\n",
    "timebuilt_df['Built'] = timebuilt_df['Rooms']\n",
    "timebuilt_df['Year'] = pd.DatetimeIndex(timebuilt_df['YearBuilt']).year\n",
    "timesold_df = melbourne_df.groupby('Date').count().reset_index()[['Date','Rooms']]\n",
    "timesold_df['Year'] = pd.DatetimeIndex(timesold_df['Date']).year\n",
    "timesold_df['Sold'] = timesold_df['Rooms']\n",
    "time_df= timebuilt_df.merge(timesold_df, on='Year', how='left')\n",
    "time_df.drop(columns=['Rooms_x', 'Rooms_y', 'YearBuilt', 'Date'], inplace=True)\n",
    "time_df=time_df.groupby('Year').sum()[['Built', 'Sold']].reset_index()\n",
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data=time_df, x='Year', y='Built');\n",
    "sns.lineplot(data=time_df, x='Year', y='Sold');\n",
    "plt.legend(labels=[\"Properties Built\", \"Properties Sold\"])\n",
    "plt.ylabel('Count')\n",
    "plt.title('Properties Sold vs Built');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using another cool function from `Plotly`, let's map the properties in Melbourne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.scatter_mapbox(melbourne_df, lat=\"Lattitude\", lon=\"Longtitude\", hover_data=[\"Price\", \"Landsize\"],\n",
    "                        color=\"Price\", size=\"Landsize\", zoom=10)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only scratched the surface of what you can do with EDA in Python. We recommend looking at functions like the [apply](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) function and the [merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) function for working with complexer queries and multiple datasets. And remember, StackOverflow and Google are your friends!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
